<!DOCTYPE html>
<html lang="en"><head>
<script src="DKT_files/libs/clipboard/clipboard.min.js"></script>
<script src="DKT_files/libs/quarto-html/tabby.min.js"></script>
<script src="DKT_files/libs/quarto-html/popper.min.js"></script>
<script src="DKT_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="DKT_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="DKT_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="DKT_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="DKT_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.550">

  <title>Module 3: Deep Knowledge Tracing</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="DKT_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="DKT_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="DKT_files/libs/revealjs/dist/theme/quarto.css">
  <link href="DKT_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="DKT_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="DKT_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="DKT_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="DKT_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="DKT_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-notes="Hi, lets talk about Deep Knowledge Tracing (DKT), and other deep learning algorithms that kind of followed since DKT. First, a quick conceptual overview of what DKT is and what made it so different." class="quarto-title-block center">
  <h1 class="title">Module 3: Deep Knowledge Tracing</h1>
  <p class="subtitle">KT Learning Lab 3: A Conceptual Overview</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="deep-knowledge-tracing-dkt-piech2015deep" class="slide level2">
<h2>Deep Knowledge Tracing (DKT) <span class="citation" data-cites="piech2015deep">Piech et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2015</a>)</span></h2>
<ul>
<li><p>Based on long short term memory networks</p></li>
<li><p>Fits on sequence of student performance across skills</p>
<ul>
<li>Predicts performance on future items within system</li>
</ul></li>
<li><p>Can fit very complex functions&nbsp;</p>
<ul>
<li>Very complex relationships between items over time</li>
</ul></li>
</ul>
<aside class="notes">
<p>Deep knowledge tracing was originally created by Pitch et al., (2015). It was based on recurrent nerual networks, specifically a variant called long-short term memory networks.&nbsp;</p>
<ul>
<li><p>It fits a sequence of student performance across skills, so a student’s performance on one skill does affect their predictions for all other skills</p></li>
<li><p>It predicts performance on future items within the system</p></li>
<li><p>It can fit very complex functions</p>
<ul>
<li><p>Compared to BKT and PFA, which generally have few enough parameters that you can count them. DKT has hundreds/thousands of parameters, so it can fit almost every type of function</p></li>
<li><p>There are very complicated relationships between the items over time</p></li>
</ul></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-knowledge-tracing-dkt" class="slide level2">
<h2>Deep Knowledge Tracing (DKT)</h2>
<ul>
<li><p>Initial paper reported massively better performance than original BKT or PFA <span class="citation" data-cites="piech2015deep">Piech et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2015</a>)</span><br>
</p></li>
<li><p>Seemed at first too good to be true, and <span class="citation" data-cites="xiong2016going">Xiong et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2016</a>)</span> reported that <span class="citation" data-cites="piech2015deep">Piech et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2015</a>)</span> had used the same data points for both training and test</p></li>
</ul>
<aside class="notes">
<p>Xiong et al., 2016 is <a href="https://files.eric.ed.gov/fulltext/ED592679.pdf" class="uri">https://files.eric.ed.gov/fulltext/ED592679.pdf</a>.&nbsp;</p>
<p>Xiong et al.&nbsp;reimplemented DKT in PyTorch and Tensorflow - TF was better - and found that while DKT still outperformed PFA and BKT, the performance gap was much smaller than earlier reported.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="contemporary-comparisons-of-dkt" class="slide level2">
<h2>Contemporary comparisons of DKT</h2>
<ul>
<li><p><span class="citation" data-cites="khajah2016deep">Khajah, Lindsey, and Mozer (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2016</a>)</span> compared DKT to modern extensions to BKT on same data set</p>
<ul>
<li>Particularly beneficial to re-fit item-skill mappings</li>
</ul></li>
<li><p><span class="citation" data-cites="wilson2016estimating">Wilson et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2016</a>)</span> compared DKT to temporal IRT on same data set</p></li>
<li><p>Bottom line: All three approaches appeared to perform comparably well</p></li>
</ul>
<aside class="notes">
<p>Khajah et al., 2016: <a href="https://arxiv.org/pdf/1604.02416.pdf" class="uri">https://arxiv.org/pdf/1604.02416.pdf</a></p>
<p>The refitting essentially collapses similar skills into one in the data. That reduces some of BKT’s disadvantage - its inability to look across skills.&nbsp;</p>
<p>IRT came from psychometrics, where you test a student at time t and there isn’t any learning going on during the test; temporal IRT adds in the possibility of learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="but-this-was-the-beginning-of-what-could-be-called-dkt-family-algorithms" class="slide level2">
<h2>But this was the beginning of what could be called&nbsp; DKT-Family algorithms</h2>
<ul>
<li><p>A range of knowledge tracing algorithms based on different variants on Deep Learning</p></li>
<li><p>Now literally hundreds of published variants</p>
<ul>
<li><p>Most of them tiny tweaks to get tiny gains in performance</p></li>
<li><p>But in aggregate, there appear to be some real improvements to predictive performance (see comparison in <span class="citation" data-cites="gervet2020deep">Gervet et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2020</a>)</span> 2020 for example)</p></li>
</ul></li>
<li><p>We will discuss some of the key issues that researchers have tried to address, and what their approaches were.</p></li>
</ul>
<aside class="notes">
<p>We’re going to be mentioning a lot of algorithms here - I think there are about 15 different ones in this presentation. Don’t worry too much about any particular one; try to pay more attention on what the author was trying to do with it.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="degenerate-behavior" class="slide level2">
<h2>Degenerate behavior</h2>
<ul>
<li><p><span class="citation" data-cites="yeung2018addressing">Yeung and Yeung (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2018</a>)</span> reported degenerate behavior for DKT</p>
<ul>
<li><p>Getting answers right leads to lower knowledge</p></li>
<li><p>Wild swings in probability estimates in short periods of time</p></li>
</ul></li>
<li><p>They proposed adding two types of regularization to moderate these swings</p>
<ul>
<li><p>Increasing weight of current prediction for future prediction</p></li>
<li><p>Reducing amount model is allowed to change future estimates</p></li>
</ul></li>
</ul>
<aside class="notes">
<p>It’s not clear how many (if any) later DKT implementations followed their lead. Unfortunately, their implementation (they called it DKTPlus) is very picky about Python library versions and tricky to get running today.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="impossible-to-interpret-in-terms-of-skills" class="slide level2">
<h2>Impossible to interpret in terms of skills</h2>
<ul>
<li><p>DKT Family generally predicts individual item correctness, not skills.</p></li>
<li><p>Some variants estimate skill ability, but those skills are not always the same as the pre-defined skills, and the estimates may not be accurate.</p></li>
</ul>
<aside class="notes">
<p>This is a departure from BKT, PFA, and most earlier algorithms.&nbsp;</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="extension-for-latent-knowledge-estimation" class="slide level2">
<h2>Extension for Latent Knowledge Estimation</h2>
<ul>
<li><p><span class="citation" data-cites="zhang2017dynamic">Jiani Zhang et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2017</a>)</span> proposed an extension to DKT, called DKVMN, that fits an item-skill mapping too</p>
<ul>
<li><p>Based on Memory-Augmented Neural Network, that keeps an external memory matrix that neurons update and refer back to&nbsp;</p></li>
<li><p>Latent skills are “discovered” by the algorithm and difficult to interpret.</p></li>
</ul></li>
</ul>
<aside class="notes">
<p>We’ll talk more about the latent skills in a bit. If you’ve done any factor analysis, you can think of them as factors - items load onto the latent skills, with each item generally loading on one skill much more than the others. The number of skills the algorithm attempts to use is a parameter, but it doesn’t have to use all of the available skills.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="extension-for-latent-knowledge-estimation-1" class="slide level2">
<h2>Extension for Latent Knowledge Estimation</h2>
<ul>
<li><p><span class="citation" data-cites="lee2019knowledge">Lee and Yeung (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2019</a>)</span> proposed an alternative to DKT, called KQN, that attempts to output more interpretable latent skill estimates</p>
<ul>
<li><p>Again, fits an external memory network to fit skills</p></li>
<li><p>Also attempts to fit amount of information transfer between skills</p></li>
<li><p>Still not that interpretable</p></li>
</ul></li>
</ul>
<aside class="notes">
<p>Both Dit-Yan Yeung and Chun-Kit Yeung, from the DKTPlus paper, worked on variants to DKVMN. Here’s the first one.</p>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3303772.3303786" class="uri">https://dl.acm.org/doi/abs/10.1145/3303772.3303786</a>&nbsp;</p>
<p>They have vector representations of skills and knowledge states, then they compute the dot product between the two to show the interaction.&nbsp;</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="extension-for-latent-knowledge-estimation-2" class="slide level2">
<h2>Extension for Latent Knowledge Estimation</h2>
<ul>
<li><p><span class="citation" data-cites="yeung2019deep">Yeung (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2019</a>)</span> proposed an alternative to DKT, called Deep-IRT, that attempts to output more interpretable latent skill estimates</p>
<ul>
<li><p>Again, fits an external memory network to fit skills</p></li>
<li><p>Fits separate networks to estimate student ability, item difficulty</p></li>
<li><p>Uses estimated ability and difficulty to predict correctness with an item response theory model.</p></li>
<li><p>Somewhat more interpretable (the IRT half, at least)</p></li>
</ul></li>
</ul>
<aside class="notes">
<p><a href="https://arxiv.org/pdf/1904.11738.pdf" class="uri">https://arxiv.org/pdf/1904.11738.pdf</a></p>
<p>The argument is that since people are used to IRT parameters, they’ll be able to understand these estimated versions. Which, well, OK, but they’re still coming out of a black box.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="one-caveat-for-skill-estimation" class="slide level2">
<h2>One caveat for skill estimation</h2>
<ul>
<li><p>Some deep learning-based algorithms attempt to estimate skill level.</p></li>
<li><p>Their skill estimates are rarely, if ever, compared to post-tests or other estimates of skill level.</p></li>
<li><p>(Most large datasets don’t have that data available)</p></li>
<li><p>Therefore, we don’t really know if the estimates are any good.</p></li>
</ul>
<aside class="notes">
<p>We just talked about DeepIRT and KQN. Both of those papers fall in this category. There are some nice graphs to explain how the skill groupings are reasonable, or how the estimated difficulties should be good, but it all comes back to the AUC of the correctness predictions in the end.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="extension-for-latent-knowledge-estimation-3" class="slide level2">
<h2>Extension for Latent Knowledge Estimation</h2>
<ul>
<li><p><span class="citation" data-cites="scruggs2019extending">Scruggs, Baker, and McLaren (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2019</a>)</span> proposed AOA, an extension to any knowledge tracing algorithm</p>
<ul>
<li><p>Human-derived skill-item mapping used</p></li>
<li><p>Predicted performance on all items in skill averaged</p>
<ul>
<li>Including both unseen and already-seen items</li>
</ul></li>
</ul></li>
<li><p>Led to successful prediction of post-tests outside the learning system</p></li>
</ul>
<aside class="notes">
<p>Where “successful” means that the Pearson correlation between the skill estimate and the posttest score on that skill ranged from 0.36 to 0.72, depending on the skill and knowledge tracing algorithm.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="latent-knowledge-estimation" class="slide level2">
<h2>Latent Knowledge Estimation</h2>
<ul>
<li><p>In unpublished work, I used DKVMN’s internal concept estimates to predict a posttest, but they were less predictive than skill estimates generated by AOA.</p></li>
<li><p>In <span class="citation" data-cites="scruggs2023well">Scruggs et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2023</a>)</span> internal skill estimates from Elo and BKT were outperformed by AOA skill estimates generated from those algorithms’ correctness predictions.</p></li>
</ul>
<aside class="notes">
<p>However, including both the internal concept estimates and AOA skill estimates produced more accurate predictions than either set of estimates alone, suggesting that the two don’t overlap completely.&nbsp;</p>
<p>(and IRT, and PFA).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery" class="slide level2">
<h2>Deep learning and skill discovery</h2>
<ul>
<li><p>Automated skill discovery would make it a lot easier to use knowledge tracing on data without skill tags.</p></li>
<li><p>It could also show relationships between skills.</p></li>
<li><p><span class="citation" data-cites="piech2015deep">Piech et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2015</a>)</span> mention that DKT accurately clustered items to skills in a synthetic data set.</p></li>
<li><p><span class="citation" data-cites="zhang2017dynamic">Jiani Zhang et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2017</a>)</span> repeat the experiment for DKVMN and also show reasonable item clusters for Assistments data.</p></li>
</ul>
<aside class="notes">
<p>The Assistments clustering was done at item level, without using skill tags. The evaluation is mostly that the clusters look good and the groupings of items seem reasonable. In a few slides, we’ll show that grouping.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery-1" class="slide level2">
<h2>Deep learning and skill discovery</h2>
<ul>
<li><p>The figures shown in <span class="citation" data-cites="zhang2017dynamic">Jiani Zhang et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2017</a>)</span> use t-SNE <span class="citation" data-cites="van2008visualizing">Van der Maaten and Hinton (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2008</a>)</span> to visualize neural network weights.</p></li>
<li><p>t-SNE is a very popular method, but the clusters it creates can be strongly influenced by the value of the perplexity parameter - lower values make t-SNE try harder to create clusters.</p></li>
<li><p>In unpublished work, I used DKVMN on a large dataset with very reliable skill tags; the resultant clusters sometimes reflect the underlying skills, but sometimes do not.</p></li>
</ul>
<aside class="notes">
<p>Piech et al.&nbsp;are a little quieter about their method - “The graph of our model’s conditional influences” is all they say, but it looks identical to Zhang et al., who say that they used t-SNE.</p>
<p>The value for that parameter isn’t usually reported in KT papers that show clusters.</p>
<p>Now I’ll show a few clusters from different algorithms and different datasets and talk about them.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery-2" class="slide level2">
<h2>Deep learning and skill discovery</h2>

<img data-src="images/Deep%20learning%20and%20skill%20discovery.png" class="r-stretch"><p>DKVMN can cluster the exercises in the Synthetic-5 dataset into their five ground-truth concepts.</p>
<aside class="notes">
<p>This is from the DKVMN paper (Zhang et al., 2017). For this figure, they explicitly set the memory size of DKVMN to five - that is, tell the model to use five underlying concepts; they show a similarly impressive figure after setting the memory size to 50 - t-SNE still clustered the exercises into five groups.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery-3" class="slide level2">
<h2>Deep learning and skill discovery</h2>

<img data-src="images/Deep%20learning%20and%20skill%20discovery2.png" class="r-stretch"><aside class="notes">
<p>These clusters come from 2009 Assistments data. They’re not quite as perfect, but there is still good separation and clearly separated clusters. Note that the colors don’t always match the clusters - colors show which of DKVMN’s internal concepts exercises load on (presumably which concept has the highest loading); clusters are generated by t-SNE based on all exercise-concept loadings.&nbsp;</p>
<p>This is from the DKVMN paper (Zhang et al., 2017).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery-4" class="slide level2">
<h2>Deep learning and skill discovery</h2>

<img data-src="images/Deep%20learning%20and%20skill%20discovery3.png" class="r-stretch"><aside class="notes">
<p>And these are the exercises that loaded onto the internal concepts. This is where I start getting skeptical. There are some reasonable-sounding groupings but plenty that don’t make intuitive sense. For example, why are the “Area”-related exercises spread across four different concepts?</p>
<p>This is from the DKVMN paper (Zhang et al., 2017).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery-5" class="slide level2">
<h2>Deep learning and skill discovery</h2>
<div class="columns">
<div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/Deep%20learning%20and%20skill%20discovery4.png"></p>
<figcaption><img data-src="images/clipboard-1155170964.png"></figcaption>
</figure>
</div>
</div><div class="column" style="width:30%;">
<p>TSNE with perplexity=5</p>
<p><br>
</p>
<p>Different colors are different skills</p>
</div>
</div>
<aside class="notes">
<p>Lower perplexity means it tries harder to make tight clusters.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skill-discovery-6" class="slide level2">
<h2>Deep learning and skill discovery</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><img data-src="images/Deep%20learning%20and%20skill%20discovery5.png"></p>
</div><div class="column" style="width:30%;">
<p>TSNE with perplexity=50</p>
<p><br>
</p>
<p>Different colors are different skills</p>
</div>
</div>
<aside class="notes">
<p>[Following the slide’s content]</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deep-learning-and-skills" class="slide level2">
<h2>Deep learning and skills</h2>
<ul>
<li><p>Finally, <span class="citation" data-cites="karumbaiah2022context">Karumbaiah, Ocumpaugh, and Baker (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2022</a>)</span> found that DKVMN’s correctness predictions were more accurate when the model had no skill tags at all (it treated all items as belonging to the same skill) than when it had possibly-unreliable skill tags, or when it had accurate domain-level tags.</p></li>
<li><p>This suggests that deep learning algorithms may be well suited for data without good skill tags.</p></li>
</ul>
<aside class="notes">
<p>I liked that finding at the time and I like it even more now that I’ve got a job in industry where there’s a lot of data that hasn’t been labeled with skill tags.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="discussion-1" class="slide level2">
<h2>Discussion 1</h2>
<ul>
<li><p>What information can DKT-family algorithms provide teachers?</p>
<ul>
<li>Is “next problem correctness” useful? Why or why not?</li>
</ul></li>
<li><p>What do you do for entirely new items?</p>
<ul>
<li>BKT and PFA fit skill-level parameters which make it much easier to add new items without retraining the model.</li>
</ul></li>
</ul>
<aside class="notes">
<p>There’s the argument that next problem correctness would let you offer problems at the “correct difficulty”. Assuming we know what that is. On the other hand, I’d argue that just showing a teacher next problem correctness is useless.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-is-dkt-really-learning" class="slide level2">
<h2>What is DKT really learning?</h2>
<ul>
<li><p><span class="citation" data-cites="ding2019deep">Ding and Larson (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2019</a>)</span> demonstrated theoretically that a lot of what DKT learns is how good a student is overall</p></li>
<li><p>They replicate that finding in a 2021 paper using a larger dataset.</p></li>
</ul>
<aside class="notes">
<p><a href="https://files.eric.ed.gov/fulltext/ED599227.pdf" class="uri">https://files.eric.ed.gov/fulltext/ED599227.pdf</a> and <a href="https://arxiv.org/pdf/2101.11335.pdf" class="uri">https://arxiv.org/pdf/2101.11335.pdf</a></p>
<p>Both of these papers are worth reading if you really want to dig into this stuff. They also show evidence that the model performance is due to projecting the items into a high-dimensional vector space.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-is-dkt-really-learning-1" class="slide level2">
<h2>What is DKT really learning?</h2>
<ul>
<li><span class="citation" data-cites="zhang2021knowledge">Jiayi Zhang et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2021</a>)</span> followed this up with empirical work showing that most of the improvement in performance for DKVMN is in the first attempt on a new skill</li>
</ul>

<img data-src="images/What%20is%20DKT%20really%20learning?.png" class="r-stretch"><aside class="notes">
<p>So what they did is that – they compared BKT with PFA and DKVMN, looking at the “cold-start problem” - how many skill attempts does it take before an algorithm’s predictions start being good? This graph shows that the traditional KT algorithms (classic BKT and PFA) lag behind DKVMN initially, but nearly catch up by attempt 3 (BKT) and 4 (PFA) respectively. This was using data from Assistments 2009.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-is-dkt-really-learning-2" class="slide level2">
<h2>What is DKT really learning?</h2>
<ul>
<li>In particular, there’s essentially no benefit to deep learning after several attempts on a skill (about where students often reach mastery, if they didn’t already know skill)</li>
</ul>

<img data-src="images/What%20is%20DKT%20really%20learning?.png" class="r-stretch"><aside class="notes">
<p>[Following the slide’s content]</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="other-important-dkt-variants-sakt" class="slide level2">
<h2>Other Important DKT Variants: SAKT</h2>
<ul>
<li><p><span class="citation" data-cites="pandey2019self">Pandey and Karypis (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2019</a>)</span> proposed a DKT variant, called SAKT, which fits attentional weights between exercises and more explicitly predicts performance on current exercise from performance on past exercises</p></li>
<li><p>Gets a little better fit, doubles down a little more on some limitations we’ve already discussed</p></li>
</ul>
<aside class="notes">
<p>I’m going to skim over the DKT variants - I think the details are not particularly important for most of them.</p>
<p>(self-attentive knowledge tracing). Neural networks folks might jump at “attentive”; yes, this uses transformers.&nbsp;</p>
<p>The idea of SAKT is that not all past skill attempts are equally relevant. The model tried to identify the most relevant past attempts, then uses those to predict the present. The paper argues that SAKT should do better on large, sparse datasets. The numbers in this paper are very good, but have not been replicated by others.</p>
<p><a href="https://arxiv.org/pdf/1907.06837.pdf" class="uri">https://arxiv.org/pdf/1907.06837.pdf</a></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="other-important-dkt-variants-akt" class="slide level2">
<h2>Other Important DKT variants: AKT</h2>
<ul>
<li><p><span class="citation" data-cites="ghosh2020context">Ghosh, Heffernan, and Lan (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2020</a>)</span> proposed a DKT variant, called AKT, which</p>
<ul>
<li><p>Explicitly stores and uses learner’s entire past practice history for each prediction</p></li>
<li><p>Uses exponential decay curve to downweight past actions</p></li>
<li><p>Uses Rasch-model embeddings to calculate item difficulty</p></li>
</ul></li>
</ul>
<aside class="notes">
<p>Context-Aware Attentive Knowledge Tracing</p>
<p>Again, attentive = transformer architecture.</p>
<p><a href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403282" class="uri">https://dl.acm.org/doi/pdf/10.1145/3394486.3403282</a></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="adding-in-more-information-saint" class="slide level2">
<h2>Adding in more information: SAINT+</h2>
<ul>
<li><span class="citation" data-cites="shin2021saint">(<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick=""><strong>shin2021saint?</strong></a>)</span>+ added elapsed time and lag time as additional inputs, leading to better performance</li>
</ul>
<aside class="notes">
<p><a href="https://dl.acm.org/doi/abs/10.1145/3448139.3448188?casa_token=VgPS4grLsw0AAAAA%3AlVHZZM7-XlW28wv9LvelO9FAcHdflBWhaeXog5nXNYd0aOcPi6H2YQ_62eOvU80PviNee8dImgU">https://dl.acm.org/doi/abs/10.1145/3448139.3448188</a>&nbsp;</p>
<p>This built off SAINT (Choi et al, 2021), another Transformer-based model with more layers than before. These algorithms were the first that were developed using EdNet data, coming from a popular English tutor app in Korea. That dataset is noteworthy for being an order of magnitude bigger - some 600K students, 72M responses, 16K exercises - than earlier datasets.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="adding-in-more-information-process-bert" class="slide level2">
<h2>Adding in more information: Process-BERT</h2>
<ul>
<li><p><span class="citation" data-cites="scarlatos2022process">Scarlatos, Brinton, and Lan (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2022</a>)</span> added timing and use of resources such as calculator<br>
</p></li>
<li><p>Additional information leads to better performance</p></li>
</ul>
<aside class="notes">
<p><a href="https://arxiv.org/pdf/2204.13607.pdf" class="uri">https://arxiv.org/pdf/2204.13607.pdf</a></p>
<p>This is meant to be a more general approach for time series data in education. Their model attempts to work on less-formatted data, first learning representations of the learning process from the data, then using those representations to predict learning outcomes. They worked with clickstream data from students completing a NAEP exam, so the data had events for (e.g.) opening the calculator, typing into an answer field, changing to a different question, etc.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="curious-methodological-note" class="slide level2">
<h2>Curious methodological note</h2>
<ul>
<li><p>Most DKT-family papers report large improvements over previous algorithms, including other DKT-family algorithms<br>
</p></li>
<li><p>Improvements that seem to mostly or entirely dissipate in the next paper</p></li>
</ul>
<aside class="notes">
<p>This is true of some of the papers listed here. For example, Ghosh et al.&nbsp;(2020) fit SAKT on some of the same datasets as Pandey and Karypis (2019), but saw much worse results.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="some-reasons" class="slide level2">
<h2>Some reasons</h2>
<ul>
<li><p>Poor validation and over-fitting</p></li>
<li><p>A lot of DKT-family papers don’t use student-level cross-validation</p>
<ul>
<li>Poor cross-validation benefits DKT-family algorithms more than other algorithms, because DKT-family fits more aggressively</li>
</ul></li>
<li><p>A lot of DKT-family papers fit their own hyperparameters but use past hyperparameters for other algorithms</p></li>
</ul>
<aside class="notes">
<p>I’m still confused about some of the cases, though; sometimes the numbers don’t match for the same algorithm on the same dataset. This is not always discussed - another reason to look at good review papers, which we’ll talk about next.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="an-evaluation" class="slide level2">
<h2>An evaluation</h2>
<ul>
<li><p><span class="citation" data-cites="gervet2020deep">Gervet et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2020</a>)</span> compares KT algorithms on several data sets</p></li>
<li><p>Key findings</p>
<ul>
<li><p>Different data sets have different winners</p></li>
<li><p>DKT-family performs better than other algorithms on large data sets, but worse on smaller data sets</p></li>
<li><p>DKT-family algorithms perform worse than LKT-family on data sets with very high numbers of practices per skill (i.e.&nbsp;language learning)</p></li>
<li><p>DKT-family algorithms do better at predicting if exact order of items matters (which can occur if items within a skill vary a lot)</p></li>
<li><p>DKT-family algorithms reach peak performance faster than other algorithms (also seen in <span class="citation" data-cites="zhang2021knowledge">Jiayi Zhang et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2021</a>)</span>)</p></li>
</ul></li>
</ul>
<aside class="notes">
<p><a href="https://jedm.educationaldatamining.org/index.php/JEDM/article/view/451" class="uri">https://jedm.educationaldatamining.org/index.php/JEDM/article/view/451</a></p>
<p>This is a good paper. If you read one DKT-related paper from here, make it this one. They try a lot of algorithms on several datasets. They also fail to replicate the SAKT results and theorize that the reported numbers are erroneous.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="another-evaluation" class="slide level2">
<h2>Another evaluation</h2>
<ul>
<li><p><span class="citation" data-cites="schmucker2021assessing">Schmucker et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2021</a>)</span> compares KT algorithms on four large datasets</p></li>
<li><p>Their feature-based logistic regression model outperformed all other approaches on nearly all datasets tested.</p></li>
<li><p>DKT was the best-performing algorithm on one dataset.&nbsp;</p></li>
<li><p>Later DKT-family variants were outperformed by standard DKT on all datasets.</p></li>
</ul>
<aside class="notes">
<p><a href="https://jedm.educationaldatamining.org/index.php/JEDM/article/view/541" class="uri">https://jedm.educationaldatamining.org/index.php/JEDM/article/view/541</a></p>
<p>“Large” = 100K+ students, 15M+ responses for all datasets.</p>
<p>This paper comes from the same lab as the earlier Gervet et al., but focuses more on their feature-based approach.</p>
<p>That last is interesting to me since I know they actually did the hyperparameters on everything.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="next-frontier-for-dkt-family-beyond-correctness" class="slide level2">
<h2>Next Frontier for DKT-family:&nbsp;Beyond Correctness</h2>
<ul>
<li>Option Tracing <span class="citation" data-cites="ghosh2021option">Ghosh, Raspat, and Lan (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2021</a>)</span> extends output layer to predict which multiple choice item the student will select</li>
</ul>
<aside class="notes">
<p><a href="https://arxiv.org/pdf/2104.09043.pdf" class="uri">https://arxiv.org/pdf/2104.09043.pdf</a></p>
<p>Works with large datasets. Doesn’t use a whole new algorithm, instead adjusts existing ones such as DKVMN to do this.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="next-frontier-for-dkt-family-beyond-correctness-1" class="slide level2">
<h2>Next Frontier for DKT-family:&nbsp;Beyond Correctness</h2>
<ul>
<li><p>Open-Ended Knowledge Tracing <span class="citation" data-cites="liu2022open">Liu et al. (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2022</a>)</span> integrates KT with&nbsp;</p>
<ul>
<li>A GPT-2 model fine-tuned on 2.1 million Java code exercises and written descriptions of them</li>
</ul></li>
<li><p>In order to generate predicted student code which makes predicted specific errors</p></li>
</ul>
<aside class="notes">
<p><a href="https://par.nsf.gov/servlets/purl/10419674" class="uri">https://par.nsf.gov/servlets/purl/10419674</a></p>
<p>Of course, since this is a fine-tuned GPT-2, it takes a ridiculous amount of training data.</p>
<p>The other interesting bit is that once you fine-tune this model, it might be able to make similar errors on unseen problems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dkt-family-work-continues" class="slide level2">
<h2>DKT-family: work continues</h2>
<ul>
<li><p>Dozens of recent papers trying to get better results by adjusting the deep learning framework in various ways&nbsp;</p></li>
<li><p>Better results = higher AUC values for predictions of next-item correctness on test data in selected datasets.</p></li>
<li><p>As shown in <span class="citation" data-cites="schmucker2022transferable">Schmucker and Mitchell (<a href="#/why-not-use-a-dkt-family-algorithm" role="doc-biblioref" onclick="">2022</a>)</span>, better results on some datasets do not always translate to better results on all datasets.</p></li>
</ul>
<aside class="notes">
<p>[Following the slide’s content]</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="discussion-2" class="slide level2">
<h2>Discussion 2</h2>
<ul>
<li><p>Is the prediction of next-problem correctness the right thing to fit on?</p>
<ul>
<li>Are there other options?</li>
</ul></li>
<li><p>How can you show that one DKT-family algorithm is better than another one?</p></li>
</ul>
<aside class="notes">
<p>Option Tracing is fitting on the student’s actual option choice, which adds something.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-to-quickly-evaluate-a-new-deep-learning-kt-algorithm" class="slide level2">
<h2>How to quickly evaluate a new deep learning KT algorithm</h2>
<ul>
<li><p>Every paper will claim great performance.</p></li>
<li><p>Look at the methods. Do they mention student-level cross-validation? Hyperparameter fitting procedures?</p>
<ul>
<li>Many won’t. That’s not always a dealbreaker. Check the code.</li>
</ul></li>
<li><p>Look at the results; find an algorithm and dataset that were also tested in another paper. Check to see if the numbers match.&nbsp;</p>
<ul>
<li>If there’s no overlap, or the numbers disagree, I’d give up on it.</li>
</ul></li>
</ul>
<aside class="notes">
<p>Since deep learning based knowledge tracing is moving so fast, it might be useful to know a few tips on how to quickly evaluate a new deep learning KT algorithm.&nbsp;</p>
<p>Ideally a good other paper.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-to-quickly-evaluate-a-new-deep-learning-kt-algorithm-1" class="slide level2">
<h2>How to quickly evaluate a new deep learning KT algorithm</h2>
<ul>
<li><p>If you actually want to use the algorithm yourself, I’d go a little deeper.</p></li>
<li><p>Download the implementation and try to replicate a result.</p></li>
<li><p>Try running it on one of the smaller Assistments datasets, making sure to use student-level cross-validation.</p></li>
<li><p>One more note: Implementation performance will vary. Some implementations are much faster than others.</p></li>
</ul>
<aside class="notes">
<p>[Following the slide’s content]</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-use-a-dkt-family-algorithm" class="slide level2">
<h2>Why use a DKT-family algorithm</h2>
<ul>
<li><p>You care about predicting next-problem correctness</p>
<ul>
<li>Or you’re willing to use a method like AOA to get skill estimates</li>
</ul></li>
<li><p>You may have unreliable skill tags, or no skill tags at all</p></li>
<li><p>Your dataset has a reasonably balanced number of attempts - or you don’t care as much about items/skills with fewer attempts</p></li>
<li><p>Your dataset has students working through material in predefined sequences</p></li>
</ul>
<aside class="notes">
<p>Finally, why use a DKT-family algorithm, and why not use one?</p>
<p>That third one seems to be often violated in real-world datasets, but people rarely talk about skill-level prediction accuracy.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-not-use-a-dkt-family-algorithm" class="slide level2 smaller scrollable">
<h2>Why not use a DKT-family algorithm</h2>
<ul>
<li><p>You want interpretable parameters</p></li>
<li><p>You have a small dataset (&lt;1M interactions)</p></li>
<li><p>You want to add new items without refitting the model.</p></li>
<li><p>You want an algorithm with more thoroughly-understood and more consistent behavior.</p></li>
</ul>
<aside class="notes">
<p>Why not use a DKT-family algorithm?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="images/LASERLogoB.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://www.go.ncsu.edu/laser-institute">go.ncsu.edu/laser-institute</a></p><a href="https://www.go.ncsu.edu/laser-institute">
</a></div><a href="https://www.go.ncsu.edu/laser-institute">
</a></div><a href="https://www.go.ncsu.edu/laser-institute">
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-ding2019deep" class="csl-entry" role="listitem">
Ding, Xinyi, and Eric C Larson. 2019. <span>“Why Deep Knowledge Tracing Has Less Depth Than Anticipated.”</span> <em>International Educational Data Mining Society</em>.
</div>
<div id="ref-gervet2020deep" class="csl-entry" role="listitem">
Gervet, Theophile, Ken Koedinger, Jeff Schneider, Tom Mitchell, et al. 2020. <span>“When Is Deep Learning the Best Approach to Knowledge Tracing?”</span> <em>Journal of Educational Data Mining</em> 12 (3): 31–54.
</div>
<div id="ref-ghosh2020context" class="csl-entry" role="listitem">
Ghosh, Aritra, Neil Heffernan, and Andrew S Lan. 2020. <span>“Context-Aware Attentive Knowledge Tracing.”</span> In <em>Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, 2330–39.
</div>
<div id="ref-ghosh2021option" class="csl-entry" role="listitem">
Ghosh, Aritra, Jay Raspat, and Andrew Lan. 2021. <span>“Option Tracing: Beyond Correctness Analysis in Knowledge Tracing.”</span> In <em>International Conference on Artificial Intelligence in Education</em>, 137–49. Springer.
</div>
<div id="ref-karumbaiah2022context" class="csl-entry" role="listitem">
Karumbaiah, Shamya, Jaclyn Ocumpaugh, and Ryan S Baker. 2022. <span>“Context Matters: Differing Implications of Motivation and Help-Seeking in Educational Technology.”</span> <em>International Journal of Artificial Intelligence in Education</em> 32 (3): 685–724.
</div>
<div id="ref-khajah2016deep" class="csl-entry" role="listitem">
Khajah, Mohammad, Robert V Lindsey, and Michael C Mozer. 2016. <span>“How Deep Is Knowledge Tracing?”</span> <em>arXiv Preprint arXiv:1604.02416</em>.
</div>
<div id="ref-lee2019knowledge" class="csl-entry" role="listitem">
Lee, Jinseok, and Dit-Yan Yeung. 2019. <span>“Knowledge Query Network for Knowledge Tracing: How Knowledge Interacts with Skills.”</span> In <em>Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge</em>, 491–500.
</div>
<div id="ref-liu2022open" class="csl-entry" role="listitem">
Liu, Naiming, Zichao Wang, Richard Baraniuk, and Andrew Lan. 2022. <span>“Open-Ended Knowledge Tracing for Computer Science Education.”</span> In <em>Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>.
</div>
<div id="ref-pandey2019self" class="csl-entry" role="listitem">
Pandey, Shalini, and George Karypis. 2019. <span>“A Self-Attentive Model for Knowledge Tracing.”</span> <em>arXiv Preprint arXiv:1907.06837</em>.
</div>
<div id="ref-piech2015deep" class="csl-entry" role="listitem">
Piech, Chris, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas J Guibas, and Jascha Sohl-Dickstein. 2015. <span>“Deep Knowledge Tracing.”</span> <em>Advances in Neural Information Processing Systems</em> 28.
</div>
<div id="ref-scarlatos2022process" class="csl-entry" role="listitem">
Scarlatos, Alexander, Christopher Brinton, and Andrew Lan. 2022. <span>“Process-BERT: A Framework for Representation Learning on Educational Process Data.”</span> <em>arXiv Preprint arXiv:2204.13607</em>.
</div>
<div id="ref-schmucker2022transferable" class="csl-entry" role="listitem">
Schmucker, Robin, and Tom M Mitchell. 2022. <span>“Transferable Student Performance Modeling for Intelligent Tutoring Systems.”</span> <em>arXiv Preprint arXiv:2202.03980</em>.
</div>
<div id="ref-schmucker2021assessing" class="csl-entry" role="listitem">
Schmucker, Robin, Jingbo Wang, Shijia Hu, and Tom M Mitchell. 2021. <span>“Assessing the Performance of Online Students–New Data, New Approaches, Improved Accuracy.”</span> <em>arXiv Preprint arXiv:2109.01753</em>.
</div>
<div id="ref-scruggs2019extending" class="csl-entry" role="listitem">
Scruggs, Richard, Ryan S Baker, and Bruce M McLaren. 2019. <span>“Extending Deep Knowledge Tracing: Inferring Interpretable Knowledge and Predicting Post-System Performance.”</span> <em>arXiv Preprint arXiv:1910.12597</em>.
</div>
<div id="ref-scruggs2023well" class="csl-entry" role="listitem">
Scruggs, Richard, Ryan S Baker, Philip I Pavlik Jr, Bruce M McLaren, and Ziyang Liu. 2023. <span>“How Well Do Contemporary Knowledge Tracing Algorithms Predict the Knowledge Carried Out of a Digital Learning Game?”</span> <em>Educational Technology Research and Development</em> 71 (3): 901–18.
</div>
<div id="ref-van2008visualizing" class="csl-entry" role="listitem">
Van der Maaten, Laurens, and Geoffrey Hinton. 2008. <span>“Visualizing Data Using t-SNE.”</span> <em>Journal of Machine Learning Research</em> 9 (11).
</div>
<div id="ref-wilson2016estimating" class="csl-entry" role="listitem">
Wilson, Kevin H, Xiaolu Xiong, Mohammad Khajah, Robert V Lindsey, Siyuan Zhao, Yan Karklin, Eric G Van Inwegen, et al. 2016. <span>“Estimating Student Proficiency: Deep Learning Is Not the Panacea.”</span> In <em>In Neural Information Processing Systems, Workshop on Machine Learning for Education</em>. Vol. 3.
</div>
<div id="ref-xiong2016going" class="csl-entry" role="listitem">
Xiong, Xiaolu, Siyuan Zhao, Eric G Van Inwegen, and Joseph E Beck. 2016. <span>“Going Deeper with Deep Knowledge Tracing.”</span> <em>International Educational Data Mining Society</em>.
</div>
<div id="ref-yeung2019deep" class="csl-entry" role="listitem">
Yeung, Chun-Kit. 2019. <span>“Deep-IRT: Make Deep Learning Based Knowledge Tracing Explainable Using Item Response Theory.”</span> <em>arXiv Preprint arXiv:1904.11738</em>.
</div>
<div id="ref-yeung2018addressing" class="csl-entry" role="listitem">
Yeung, Chun-Kit, and Dit-Yan Yeung. 2018. <span>“Addressing Two Problems in Deep Knowledge Tracing via Prediction-Consistent Regularization.”</span> In <em>Proceedings of the Fifth Annual ACM Conference on Learning at Scale</em>, 1–10.
</div>
<div id="ref-zhang2017dynamic" class="csl-entry" role="listitem">
Zhang, Jiani, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2017. <span>“Dynamic Key-Value Memory Networks for Knowledge Tracing.”</span> In <em>Proceedings of the 26th International Conference on World Wide Web</em>, 765–74.
</div>
<div id="ref-zhang2021knowledge" class="csl-entry" role="listitem">
Zhang, Jiayi, Rohini Das, Ryan Baker, and Richard Scruggs. 2021. <span>“Knowledge Tracing Models’ Predictive Performance When a Student Starts a Skill.”</span> In <em>Proceedings of the 14th International Conference on Educational Data Mining. EDM, Paris, France</em>, 625–29.
</div>
</div>
</a></section><a href="https://www.go.ncsu.edu/laser-institute">
    </a></div><a href="https://www.go.ncsu.edu/laser-institute">
  </a></div><a href="https://www.go.ncsu.edu/laser-institute">

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="DKT_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="DKT_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="DKT_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="DKT_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 5.0e-2,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</a></body></html>